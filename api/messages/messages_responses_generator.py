import os

from flask import Request, Response
from dotenv import load_dotenv
from torch import Tensor

from api.messages.data_construction.data_builder import DataBuilder
from api.messages.data_construction.stop_words_cleaner import StopWordsCleaner
from api.messages.data_construction.syntax_cleaner import SyntaxCleaner
from api.messages.data_construction.lemmatizer import Lemmatizer
from api.proxy.proxy_interface import ProxyInterface
from api.common.response_formatter import ResponseFormatter
from api.messages.intent_recognition.intent_recognizer_factory import IntentRecognizerFactory
from api.messages.intent_recognition.transformer_based_similarity_network import TransformerBasedSimilarityNetwork
from api.messages.intent_recognition.data_types.intent_recognizer_input_data import IntentRecognizerInputData
from api.messages.intent_recognition.data_types.similarity_based_input_data import SimilarityBasedInputData
from api.messages.intent_recognition.data_types.intent_recognizer_response import IntentRecognizerResponse
from api.messages.intent_recognition.data_types.similarity_based_response import SimilarityBasedResponse
from api.messages.intent_recognition.transformer_based_similarity_network_factory import \
    TransformerBasedSimilarityNetworkFactory


class MessagesResponsesGenerator(ProxyInterface):
    """Messages responses generator service that is responsible for searching a response based on a user's intent."""

    # Load environment variables
    load_dotenv()

    # Confidence limits used by a similarity based intent recognizer
    _confidence_limit: float = float(os.getenv('CONFIDENCE_LIMIT'))
    _suggestion_limit: float = float(os.getenv('SUGGESTION_LIMIT'))

    # Maximum number of suggestions given by the chatbot
    _max_suggestions_number: int = int(os.getenv('MAX_SUGGESTIONS_NUMBER'))

    def __init__(self):
        # Most relevant documents found
        self._most_relevant_documents: list[dict] = []

    def handle_request(self, user_request: Request) -> Response:
        """
        Manage a message request submitted a users to give an adequate response.

        :param user_request: A message request submitted by a user.
        :return: The response generated by the messages service.
        """

        # Create an intent recognizer
        intent_recognizer: TransformerBasedSimilarityNetwork = TransformerBasedSimilarityNetworkFactory().create_recognizer()

        # Create data construction objects to build data
        syntax_cleaner: DataBuilder = SyntaxCleaner()
        stop_words_cleaner: DataBuilder = StopWordsCleaner()
        lemmatizer: DataBuilder = Lemmatizer()

        syntax_cleaner.set_next_builder(stop_words_cleaner)
        stop_words_cleaner.set_next_builder(lemmatizer)

        # Get user message from user request
        user_message: str = user_request.get_json()['user_message']
        user_message = syntax_cleaner.build_data([user_message]).pop()

        # Get user message embeddings representation
        message_embeddings: Tensor = intent_recognizer.get_embeddings([user_message])

        # Get documents from a database
        from api.persistence_requests import data_importer
        documents: list[dict] = data_importer.documents

        # Create an intent recognizer factory
        intent_recognizer_factory: IntentRecognizerFactory = TransformerBasedSimilarityNetworkFactory()

        # Iterate each document to process the user intent with its training data
        for document in documents:
            # Get the embeddings representation of the current document
            document_embeddings = document['embeddings']

            # Process the user message to try to get its intent
            intent_data: IntentRecognizerInputData = SimilarityBasedInputData(
                user_message,
                self._confidence_limit,
                message_embeddings,
                document_embeddings
            )

            intent_result: IntentRecognizerResponse | SimilarityBasedResponse = \
                intent_recognizer_factory.process_user_intent(intent_data)

            self._save_suggestion(intent_result.max_similarity_value, document)

        # pycode: noqa
        if (
            len(self._most_relevant_documents) > 0
            and self._most_relevant_documents[0]['similarity_value'] > self._confidence_limit
        ):
            for document in documents:
                # Give a response based on a found document
                if document['id'] == self._most_relevant_documents[0]['document_id']:
                    return ResponseFormatter.get_recognized_response(document)

        return self._handle_suggestions_response()

    def _save_suggestion(self, similarity_value: float, document: dict):
        """
        Save a relevant suggestion according to the defined limit.

        :param similarity_value: The similarity value of the current document.
        :param document: The current document that will be saved.
        """

        ignored_documents = ['Saludos', 'Agradecimientos']

        # Verify that the similarity value is appropriate
        if similarity_value >= self._suggestion_limit:
            self._most_relevant_documents.append(
                {
                    'similarity_value': similarity_value,
                    'document_id': document['id'],
                    'document_title': document['title'],
                    'response_set_id': document['response_set_id'],
                    'visibility': True if document['title'] not in ignored_documents else False
                }
            )

            # Sort documents by relevance
            self._most_relevant_documents = sorted(
                self._most_relevant_documents, key=lambda x: x['similarity_value'], reverse=True
            )

            # Limit number of relevant documents
            self._most_relevant_documents = self._most_relevant_documents[:self._max_suggestions_number]

    def _handle_suggestions_response(self) -> Response:
        """
        Give suggestions when intent is not recognized.

        :return: A response with most relevant suggestions.
        """

        # Ignore documents that are set to not visible
        filtered_suggestions = list(filter(
            lambda x: x['visibility'],
            self._most_relevant_documents
        ))

        if len(filtered_suggestions) > 0:
            suggestions = {
                "id": "sugerencias",
                "title": "Sugerencias",
                "responses": []
            }

            # Give a default text message for suggestions
            suggestions['responses'].append(
                {
                    "type": "text",
                    "content": "Lamentablemente, no logro entender tu mensaje. "
                               "¿Podría ser que quisieras hablar sobre alguno de estos temas?"
                }
            )

            # Format suggestions into a suggestions document
            suggestions['responses'].extend(
                map(lambda relevant_document: {
                    "type": "action",
                    "action": relevant_document['document_id'],
                    "name": relevant_document['document_title']
                }, filtered_suggestions)
            )

            # Give suggestions
            return ResponseFormatter.get_recognized_response(suggestions)

        # Give a no recognized intent
        return ResponseFormatter.get_no_recognized_response()
